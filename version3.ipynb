{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "改动最多的版本，score：0.42868，文件为submission3.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "from sklearn.metrics import make_scorer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "SEED = 2021\n",
    "set_seed(SEED)\n",
    "is_scale = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Timeline类\n",
    "初始化，用于记录每天的节日、工作日、油价等情况"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class Timeline:\n",
    "    def __init__(self):\n",
    "        self.timeline = pd.DataFrame(index=pd.date_range('2013-01-01', '2017-08-31')).to_period('D')\n",
    "        self.holiday = None\n",
    "\n",
    "    def get_oil(self, file_path):\n",
    "        oil = pd.read_csv(file_path,\n",
    "                          parse_dates=['date'], infer_datetime_format=True,\n",
    "                          index_col='date').to_period('D')\n",
    "        # 用0填充NaN（Not a number）\n",
    "        oil['dcoilwtico'] = np.where(oil['dcoilwtico'] == 0, np.nan, oil['dcoilwtico'])\n",
    "        # 作插值计算\n",
    "        oil['dcoilwtico'] = oil.dcoilwtico.interpolate()\n",
    "        # 计算每7天的均值\n",
    "        oil['mean_oil'] = oil['dcoilwtico'].rolling(7).mean()\n",
    "        self.timeline = self.timeline.join(oil.mean_oil)\n",
    "        self.timeline.fillna(method='ffill', inplace=True)\n",
    "        self.timeline.dropna(inplace=True)\n",
    "\n",
    "    def get_Holidays(self, file_path):\n",
    "        holiday = pd.read_csv(file_path,\n",
    "                              parse_dates=['date'], infer_datetime_format=True,\n",
    "                              index_col='date').to_period('D')\n",
    "        holiday = holiday.sort_index()\n",
    "        holiday = holiday[holiday['locale'] == 'National']  # 只考虑国际节日\n",
    "        self.holiday = holiday.groupby(holiday.index).first()  # 每天只保留一个节日信息\n",
    "\n",
    "    def get_Workday(self):\n",
    "        self.timeline = self.timeline.join(self.holiday)\n",
    "        self.timeline['dayofweek'] = self.timeline.index.dayofweek\n",
    "        self.timeline['workday'] = True\n",
    "        self.timeline.loc[self.timeline['dayofweek'] > 4, 'workday'] = False\n",
    "        self.timeline.loc[self.timeline['type'] == 'Work Day', 'workday'] = True\n",
    "        self.timeline.loc[self.timeline['type'] == 'Transfer', 'workday'] = False\n",
    "        self.timeline.loc[self.timeline['type'] == 'Bridge', 'workday'] = False\n",
    "        self.timeline.loc[\n",
    "            (self.timeline['type'] == 'Holiday') & (self.timeline['transferred'] == False), 'workday'] = False\n",
    "        self.timeline.loc[\n",
    "            (self.timeline['type'] == 'Holiday') & (self.timeline['transferred'] == True), 'workday'] = True\n",
    "        self.timeline = pd.get_dummies(self.timeline, columns=['type'])\n",
    "        self.timeline.drop(['locale', 'locale_name', 'description', 'transferred'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "T = Timeline()\n",
    "T.get_oil('data/oil.csv')\n",
    "T.get_Holidays('data/holidays_events.csv')\n",
    "T.get_Workday()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取数据，`parse_dates`为将指定列解析为`datetime64[ns]`数据类型，`infer_datetime_format`的作用为加速时间列解析速度\n",
    "将`store_nbr`指定为`object`数据类型，并从`train.csv`中选取`date`,`store_nbr`,`family`,`sales`四列数据读入变量`train`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv',\n",
    "                    parse_dates=['date'], infer_datetime_format=True,\n",
    "                    dtype={'store_nbr': 'object'},\n",
    "                    usecols=['date', 'store_nbr', 'family', 'sales'])\n",
    "train['date'] = train.date.dt.to_period('D')\n",
    "train = train.set_index(['date', 'store_nbr', 'family']).sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv',\n",
    "                   parse_dates=['date'], infer_datetime_format=True,\n",
    "                   dtype={'store_nbr': 'object'},\n",
    "                   usecols=['date', 'store_nbr', 'family'])\n",
    "test['date'] = test.date.dt.to_period('D')\n",
    "test = test.set_index(['date', 'store_nbr', 'family']).sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练样本清洗"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "train_date_start = '2017-04-01'\n",
    "train_date_end = '2017-08-15'\n",
    "y_raw = train.unstack(['store_nbr', 'family']).loc[train_date_start:train_date_end]\n",
    "\n",
    "fourier = CalendarFourier(freq='W', order=4)\n",
    "\n",
    "dp = DeterministicProcess(index=y_raw.index,\n",
    "                          constant=False,\n",
    "                          order=1,\n",
    "                          seasonal=False,\n",
    "                          additional_terms=[fourier],\n",
    "                          drop=True)\n",
    "X_raw = dp.in_sample()\n",
    "\n",
    "X_raw['mean_oil'] = T.timeline.loc[train_date_start:train_date_end]['mean_oil'].values\n",
    "X_raw['dayofweek'] = T.timeline.loc[train_date_start:train_date_end]['dayofweek'].values\n",
    "X_raw['workday'] = T.timeline.loc[train_date_start:train_date_end]['workday'].values\n",
    "X_raw = X_raw.join(T.timeline.loc[train_date_start:train_date_end, 'type_Additional':'type_Work Day'])\n",
    "X_raw = pd.get_dummies(X_raw, columns=['dayofweek'], drop_first=True)\n",
    "# X.drop('trend', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "test_date_start = '2017-08-16'\n",
    "test_date_end = '2017-08-31'\n",
    "\n",
    "X_test = dp.out_of_sample(steps=16)\n",
    "\n",
    "X_test['mean_oil'] = T.timeline.loc[test_date_start:test_date_end]['mean_oil'].values\n",
    "X_test['dayofweek'] = T.timeline.loc[test_date_start:test_date_end]['dayofweek'].values\n",
    "X_test['workday'] = T.timeline.loc[test_date_start:test_date_end]['workday'].values\n",
    "X_test = X_test.join(T.timeline.loc[test_date_start:test_date_end, 'type_Additional':'type_Work Day'])\n",
    "X_test = pd.get_dummies(X_test, columns=['dayofweek'], drop_first=True)\n",
    "# X_test.drop('trend', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 归一化（可选）\n",
    "如需进行归一化操作，则令`is_scale=True`即可"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "if is_scale:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X_raw)\n",
    "    y_scaled = scaler_y.fit_transform(y_raw)\n",
    "    X_test_scaled = scaler_X.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练函数\n",
    "\n",
    "`train_model`函数用于网格化搜索确定模型最优参数，正式预测中不再使用"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def my_score(y, y_pred):\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y_raw.columns)\n",
    "    y_pred = y_pred.stack(['store_nbr', 'family']).clip(0.)\n",
    "    y_ = pd.DataFrame(y, columns=y_raw.columns)\n",
    "    y_ = y_.stack(['store_nbr', 'family'])\n",
    "    rmse = np.sqrt(np.sqrt(msle(y_['sales'], y_pred['sales'])))\n",
    "    print(f'rmse:{rmse}')\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def train_model(model, gridsearch_params, X, y):\n",
    "    # 通过train_model进行调参，确定模型最优参数\n",
    "    gridsearch = GridSearchCV(model, gridsearch_params, cv=3,\n",
    "                              scoring=make_scorer(my_score, greater_is_better=False),\n",
    "                              verbose=1, return_train_score=True)\n",
    "    gridsearch.fit(X, y)\n",
    "    model = gridsearch.best_estimator_\n",
    "    y_pred = model.predict(X)\n",
    "    print('------------')\n",
    "    print(model)\n",
    "    print('------------')\n",
    "    print(f'rmse={my_score(y, y_pred)}')\n",
    "    return model\n",
    "\n",
    "def create_Model(X, y):\n",
    "    ridge = Ridge(alpha=0.75, random_state=SEED)\n",
    "    svr = SVR(C=0.2)\n",
    "    root1 = ExtraTreesRegressor(n_estimators = 200, random_state=SEED)\n",
    "    root2 = RandomForestRegressor(n_estimators = 200, random_state=SEED)\n",
    "    gbdt = GradientBoostingRegressor(n_estimators = 200, random_state=SEED)\n",
    "    # model = train_model(lasso, param_grid, X_raw, y_raw)\n",
    "    model = VotingRegressor([('ridge', ridge), ('svr', svr), ('extra', root1), ('rf', root2), ('gbdt', gbdt)])\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def model_fit(X, y):\n",
    "    if type(X) == np.ndarray:\n",
    "        estimators = Parallel(n_jobs=-1,\n",
    "                              verbose=0)(delayed(create_Model)(X, y[:, i]) for i in tqdm(range(y.shape[1])))\n",
    "    else:\n",
    "        estimators = Parallel(n_jobs=-1,\n",
    "                              verbose=0)(delayed(create_Model)(X, y.iloc[:, i]) for i in tqdm(range(y.shape[1])))\n",
    "    return estimators\n",
    "\n",
    "def predict(estimators_, X):\n",
    "    y_pred = Parallel(n_jobs=-1,\n",
    "                      verbose=0)(delayed(e.predict)(X) for e in tqdm(estimators_))\n",
    "    return np.stack(y_pred, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 函数拟合"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1782 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0476c677c0b94b4b96eeb7b9d023396a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_scale:\n",
    "    model = model_fit(X_scaled, y_scaled)\n",
    "else:\n",
    "    model = model_fit(X_raw, y_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 预测输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1782 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9707a1c56054e91bcce3a79a4e86549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_scale:\n",
    "    y_pred = predict(model, X_test_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "else:\n",
    "    y_pred = predict(model, X_test)\n",
    "y_pred = pd.DataFrame(y_pred, index=X_test.index, columns=y_raw.columns).clip(0.)\n",
    "y_pred = y_pred.stack(['store_nbr', 'family'])\n",
    "submit_file = pd.read_csv('data/sample_submission.csv')\n",
    "submit_file['sales'] = y_pred.values\n",
    "submit_file.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
